check my code for why this ai chatbot may not work as expected. i think you can clearly see what i want it to do from the prompt engineering, but it continues to ask the same kind of questions over and over again without remembering informations or finalising like it is supposed to after macimally 3 wuestions

AI
AI
just now
To address the issue with your AI chatbot repeatedly asking the same questions and not finalizing, here are some potential reasons and solutions based on the code snippets provided:

Potential Reasons and Solutions
Session Management:
Ensure that the session is correctly set up and persists across requests. Flask requires a secret key to manage sessions, and data stored in session should be updated and retrieved correctly.
Verify that session['chat_history'] and other session variables like session['patient_summary'] are updated properly after each interaction.
Question Count Logic:
Verify that count_assistant_questions(chat_history) correctly counts questions each time without mistakenly resetting or excluding questions based on how they're logged or formatted in chat_history.
Finalization Condition:
Check if questions_asked is accurately calculated and crossing the threshold intended to trigger finalization.
Ensure get_finalization_response(patient_summary) is called correctly when questions_asked >= 3.
Update and Persistence in Chat History:
Ensure each new question and response is correctly appended to chat_history.
Correct Use of SYSTEM_PROMPT and Memory:
Ensure SYSTEM_PROMPT and context are correctly updated at each request. Messages passed to the OpenAI model should incorporate remembered context as structured logs, as the model itself doesnâ€™t store session memory inherently.
Error Handling and Logging:
Add logging to track flow and state. Check if exceptions occur during API calls or message processing and look for warnings or relevant errors which could disrupt flow.
Validation of OpenAI Integration:
Verify parameters and API call success with OpenAI, ensuring responses match expected formats and no network issues are affecting output.
Here's some logging you could add to better understand and debug the flow:

import logging
logging.basicConfig(level=logging.DEBUG)
def chat():
    try:
        user_message = request.json.get('message')
        logging.debug(f"Received user message: {user_message}")
        chat_history = get_chat_history()
        patient_summary = update_patient_summary(user_message)
        questions_asked = count_assistant_questions(chat_history)
        logging.debug(f"Questions asked: {questions_asked}")
        if questions_asked >= 3:
            ai_response = get_finalization_response(patient_summary)
        else:
            # ... [your existing message handling logic] ...
            ai_response = openai.ChatCompletion.create(
                model="gpt-4o",
                messages=messages
            )
        
        response_content = ai_response['choices'][0]['message']['content']
        logging.debug(f"AI response: {response_content}")
        session['chat_history'].append({'type': 'assistant', 'content': response_content})
        return jsonify({'response': response_content})
    except Exception as e:
        logging.error(f"Error in chat processing: {str(e)}")
        return jsonify({'error': str(e)}), 500
By logging inputs, outputs, and critical variables, you'll be better equipped to identify where the logic diverges from expectations and take corrective action.